{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader, StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "import nest_asyncio\n",
    "import hashlib\n",
    "import json\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Llama Parsing\n",
    "parser = LlamaParse(\n",
    "    api_key=os.getenv(\"LLAMA_CLOUD_API_KEY\"),\n",
    "    result_type=\"markdown\"  # \"markdown\" and \"text\" are available\n",
    ")\n",
    "file_extractor = {\".pdf\": parser}\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open AI setup\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "#Pinecone setup\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "#Pinecone index name\n",
    "index_name = 'ai-tutor'\n",
    "#Add the embeddings to the index\n",
    "#Did this if statement because earlier I was re-running the code and it was outputting error so I added this if statement to check if the index is already created or not\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File test_parsing/deeplearningbook.org_contents_part_basics.html.pdf has already been processed. Using existing index.\n",
      "\n",
      "Testing query...\n",
      "Query: Can you give me first 3 sentences of the deep learning book?\n",
      "Response: This part of the book introduces the basic mathematical concepts needed to understand deep learning. We begin with general ideas from applied math that enable us to define functions of many variables, find the highest and lowest points on these functions, and quantify degrees of belief. Next, we describe the fundamental goals of machine learning.\n"
     ]
    }
   ],
   "source": [
    "#Hashing file setup\n",
    "UPLOAD_DOCS_FILE = 'upload_docs.json'\n",
    "\n",
    "\n",
    "def get_file_hash(file_path):\n",
    "    #Generate a hash for the file to use as an unique indentifier\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        #Hashlib.md5() makes that file don't have to be stored in memory\n",
    "        file_hash = hashlib.md5()\n",
    "        chunk = f.read(8192)\n",
    "        while chunk:\n",
    "            file_hash.update(chunk)\n",
    "            chunk = f.read(8192)\n",
    "    return file_hash.hexdigest()\n",
    "\n",
    "\n",
    "#Load the file hashes\n",
    "def load_uploaded_dos():\n",
    "    #Load the list of upload documents\n",
    "    if os.path.exists(UPLOAD_DOCS_FILE):\n",
    "        with open(UPLOAD_DOCS_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "\n",
    "#save the file hashes\n",
    "def save_uploaded_docs(uploaded_docs):\n",
    "    with open(UPLOAD_DOCS_FILE, 'w') as f:\n",
    "        json.dump(uploaded_docs, f)\n",
    "\n",
    "\n",
    "#Processing the PDF file\n",
    "def process_pdf(file_path, index_name, pc):\n",
    "    #Get the file hash\n",
    "    file_hash = get_file_hash(file_path)\n",
    "    #Check if the file is already uploaded\n",
    "    upload_file_docs = load_uploaded_dos()\n",
    "\n",
    "    if file_hash in upload_file_docs:\n",
    "        print(f\"File {file_path} has already been processed. Using existing index.\")\n",
    "        return get_existing_index(index_name,pc)\n",
    "\n",
    "    #If the file has not been upserted then we will process the file\n",
    "    documents = SimpleDirectoryReader(input_files=[file_path], file_extractor=file_extractor).load_data()\n",
    "    vector_store = PineconeVectorStore(pinecone_index=pc.Index(index_name))\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "\n",
    "    #Update the file hash\n",
    "    upload_file_docs[file_hash] = {'file_path': file_path, 'index': index.to_dict()}\n",
    "    save_uploaded_docs(upload_file_docs)\n",
    "\n",
    "    return index\n",
    "\n",
    "#Get existing index\n",
    "def get_existing_index(index_name, pc):\n",
    "    vector_store = PineconeVectorStore(pinecone_index=pc.Index(index_name))\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    return VectorStoreIndex.from_vector_store(vector_store=vector_store,storage_context=storage_context)\n",
    "\n",
    "\n",
    "#Generate a response \n",
    "def generate_response(query, index):\n",
    "    retriever = index.as_retriever(similarity_top_k=3)\n",
    "    retrieved_nodes = retriever.retrieve(query)\n",
    "    context='\\n'.join([node.node.text for node in retrieved_nodes])\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a knowledgeable AI tutor. Use the provided context to answer the question.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "#This function will be called in future NextJS API route to process the PDF\n",
    "def handle_pdf(filepath):\n",
    "    return process_pdf(filepath, index_name, pc)\n",
    "\n",
    "\n",
    "#This function will be called from API route as well, as the output\n",
    "def handle_query(query):\n",
    "    index = get_existing_index(index_name, pc)\n",
    "    response = generate_response(query, index)\n",
    "    return response\n",
    "\n",
    "\n",
    "#Testing if it works\n",
    "def test_pdf_processing_and_query():\n",
    "    handle_pdf('test_parsing/deeplearningbook.org_contents_part_basics.html.pdf')\n",
    "    print('\\nTesting query...')\n",
    "    query = \"Can you give me first 3 sentences of the deep learning book?\"\n",
    "    response = handle_query(query)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Response: {response}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_pdf_processing_and_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-tutor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
